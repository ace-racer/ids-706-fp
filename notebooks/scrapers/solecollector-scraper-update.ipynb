{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = False\n",
    "solecollector_com = 'https://solecollector.com'\n",
    "textify = lambda x: x.text\n",
    "stripify = lambda x: x.strip()\n",
    "sneaker_keys = ['id', 'name', 'date_created', 'date_updated', 'alias', 'release_date', 'images', \n",
    "                'description', 'style_code', 'original_price', 'hero_image', 'available_at', 'url', \n",
    "                'release_day', 'release_month', 'hero_image_url', 'hero_image_id', 'release_date_pretty', \n",
    "                'original_price_pretty', 'hero_image_alt', 'canonical_url']\n",
    "\n",
    "sneaker_json = []\n",
    "brand_json = []\n",
    "secondary_brand_json = []\n",
    "silhouette_json = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve date information to automate url generation\n",
    "year = datetime.datetime.now().year\n",
    "month = datetime.datetime.now().month\n",
    "\n",
    "urls = f'https://solecollector.com/sneaker-release-dates/all-release-dates/{year}/{month}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sneaker_soup, sneaker_script):\n",
    "    \n",
    "    # Obtain data on brand, secondary brand, and silhouette\n",
    "    no_additional_data = False\n",
    "    query1 = re.search('var sneaker_path = (.+)[,;]{1}', sneaker_script)\n",
    "    if query1:\n",
    "        query1_data = json.loads(query1.group(1))\n",
    "        \n",
    "        brand = query1_data[0]\n",
    "        secondary_brand = query1_data[1]\n",
    "        silhouette = query1_data[2]\n",
    "        \n",
    "        brand_id = brand['id']\n",
    "        secondary_brand_id = secondary_brand['id']\n",
    "        silhouette_id = silhouette['id']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        no_additional_data = True\n",
    "        brand_id = np.nan\n",
    "        secondary_brand_id = np.nan\n",
    "        silhouette_id = np.nan\n",
    "    \n",
    "    # Obtain data on sneaker\n",
    "    query2 = re.search('var sneaker_release = (.+)[,;]{1}', sneaker_script)\n",
    "    if query2:\n",
    "        sneaker = json.loads(query2.group(1))\n",
    "        sneaker['brand_id'] = brand_id\n",
    "        sneaker['secondary_brand_id'] = secondary_brand_id\n",
    "        sneaker['silhouette_id'] = silhouette_id\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        sneaker_values = sneaker_soup.find_all('div', class_='sd-brand-info__value')\n",
    "        sneaker_values = list(map(textify, sneaker_values))\n",
    "        sneaker_values = list(map(stripify, sneaker_values))\n",
    "        \n",
    "        sneaker = {key: np.nan for key in sneaker_keys} \n",
    "        sneaker['brand_id'] = brand_id\n",
    "        sneaker['secondary_brand_id'] = secondary_brand_id\n",
    "        sneaker['silhouette_id'] = silhouette_id\n",
    "        sneaker['release_date_pretty'] = sneaker_values[0]\n",
    "        sneaker['style_code'] = sneaker_values[1]\n",
    "        sneaker['name'] = sneaker_values[2]\n",
    "        sneaker['original_price_pretty'] = sneaker_values[3]\n",
    "        \n",
    "    if no_additional_data == False:\n",
    "        sneaker_json.append(sneaker)\n",
    "        brand_json.append(brand)\n",
    "        secondary_brand_json.append(secondary_brand)\n",
    "        silhouette_json.append(silhouette)\n",
    "        \n",
    "    else:\n",
    "        sneaker_json.append(sneaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_url = urls\n",
    "\n",
    "try:\n",
    "    source = requests.get(current_url, time.sleep(3)).text\n",
    "except:\n",
    "    pass\n",
    "\n",
    "source_soup = BeautifulSoup(source)\n",
    "monthly_sneakers = source_soup.find_all('div', class_='col-xs-12 col-sm-6') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sneaker in enumerate(monthly_sneakers):\n",
    "    if index % 2:\n",
    "        continue\n",
    "\n",
    "    sneaker_url = solecollector_com + monthly_sneakers[index].a['href']\n",
    "    sneaker_html = requests.get(sneaker_url).text\n",
    "    sneaker_soup = BeautifulSoup(sneaker_html)\n",
    "\n",
    "    try:\n",
    "        sneaker_script = str(sneaker_soup.find_all('script', type=\"text/javascript\")[2])\n",
    "    except IndexError:\n",
    "        break\n",
    "    get_data(sneaker_soup, sneaker_script)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "data = Path(dir)\n",
    "data = data / \"..\" / \"..\" / \"data\" / \"01_raw\"/ \"update\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data / 'sneaker.json', 'w') as outfile:\n",
    "    json.dump(sneaker_json, outfile)\n",
    "\n",
    "sneaker_df = pd.DataFrame(sneaker_json)\n",
    "sneaker_df = sneaker_df.sort_values(by='release_date', ascending=False)\n",
    "sneaker_df = sneaker_df.drop_duplicates(subset=['id'])\n",
    "sneaker_df = sneaker_df.drop_duplicates(subset=['style_code'])\n",
    "sneaker_df.to_csv(data / 'sneaker.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data / 'brand.json', 'w') as outfile:\n",
    "    json.dump(brand_json, outfile)\n",
    "\n",
    "brand_df = pd.DataFrame(brand_json)\n",
    "brand_df = brand_df.sort_values(by='id', ascending=True)\n",
    "brand_df = brand_df.drop_duplicates(subset=['id'])\n",
    "brand_df.to_csv(data / 'brand.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data / 'secondary_brand.json', 'w') as outfile:\n",
    "    json.dump(secondary_brand_json, outfile)\n",
    "\n",
    "secondary_brand_df = pd.DataFrame(secondary_brand_json)\n",
    "secondary_brand_df = secondary_brand_df.sort_values(by='id', ascending=True)\n",
    "secondary_brand_df = secondary_brand_df.drop_duplicates(subset=['id'])\n",
    "secondary_brand_df.to_csv(data / 'secondary_brand.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data / 'silhouette.json', 'w') as outfile:\n",
    "    json.dump(silhouette_json, outfile)\n",
    "\n",
    "silhouette_df = pd.DataFrame(silhouette_json)\n",
    "silhouette_df = silhouette_df.sort_values(by='id', ascending=True)\n",
    "silhouette_df = silhouette_df.sort_values(by='id', ascending=True)\n",
    "silhouette_df.to_csv(data / 'silhouette.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
