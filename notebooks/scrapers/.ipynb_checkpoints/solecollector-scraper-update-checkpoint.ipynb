{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = False\n",
    "solecollector_com = 'https://solecollector.com'\n",
    "textify = lambda x: x.text\n",
    "stripify = lambda x: x.strip()\n",
    "sneaker_keys = ['id', 'name', 'date_created', 'date_updated', 'alias', 'release_date', 'images', \n",
    "                'description', 'style_code', 'original_price', 'hero_image', 'available_at', 'url', \n",
    "                'release_day', 'release_month', 'hero_image_url', 'hero_image_id', 'release_date_pretty', \n",
    "                'original_price_pretty', 'hero_image_alt', 'canonical_url']\n",
    "\n",
    "sneaker_json = []\n",
    "brand_json = []\n",
    "secondary_brand_json = []\n",
    "silhouette_json = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve date information to automate url generation\n",
    "current_year = datetime.datetime.now().year\n",
    "current_month = datetime.datetime.now().month\n",
    "\n",
    "current_months = [str(x).zfill(2) for x in range(1, current_month+1)]\n",
    "all_months = [str(x).zfill(2) for x in range(1, 13)]\n",
    "all_years = [str(x) for x in range(2011, current_year+1)]\n",
    "dates_dict = {year:all_months for year in all_years}\n",
    "dates_dict[str(current_year)] = current_months\n",
    "\n",
    "# generate  \n",
    "urls = []\n",
    "for year, months in dates_dict.items():\n",
    "    for month in months:\n",
    "        urls.append(f'https://solecollector.com/sneaker-release-dates/all-release-dates/{year}/{month}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sneaker_soup, sneaker_script):\n",
    "    \n",
    "    # Obtain data on brand, secondary brand, and silhouette\n",
    "    no_additional_data = False\n",
    "    query1 = re.search('var sneaker_path = (.+)[,;]{1}', sneaker_script)\n",
    "    if query1:\n",
    "        query1_data = json.loads(query1.group(1))\n",
    "        \n",
    "        brand = query1_data[0]\n",
    "        secondary_brand = query1_data[1]\n",
    "        silhouette = query1_data[2]\n",
    "        \n",
    "        brand_id = brand['id']\n",
    "        secondary_brand_id = secondary_brand['id']\n",
    "        silhouette_id = silhouette['id']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        no_additional_data = True\n",
    "        brand_id = np.nan\n",
    "        secondary_brand_id = np.nan\n",
    "        silhouette_id = np.nan\n",
    "    \n",
    "    # Obtain data on sneaker\n",
    "    query2 = re.search('var sneaker_release = (.+)[,;]{1}', sneaker_script)\n",
    "    if query2:\n",
    "        sneaker = json.loads(query2.group(1))\n",
    "        sneaker['brand_id'] = brand_id\n",
    "        sneaker['secondary_brand_id'] = secondary_brand_id\n",
    "        sneaker['silhouette_id'] = silhouette_id\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        sneaker_values = sneaker_soup.find_all('div', class_='sd-brand-info__value')\n",
    "        sneaker_values = list(map(textify, sneaker_values))\n",
    "        sneaker_values = list(map(stripify, sneaker_values))\n",
    "        \n",
    "        sneaker = {key: np.nan for key in sneaker_keys} \n",
    "        sneaker['brand_id'] = brand_id\n",
    "        sneaker['secondary_brand_id'] = secondary_brand_id\n",
    "        sneaker['silhouette_id'] = silhouette_id\n",
    "        sneaker['release_date_pretty'] = sneaker_values[0]\n",
    "        sneaker['style_code'] = sneaker_values[1]\n",
    "        sneaker['name'] = sneaker_values[2]\n",
    "        sneaker['original_price_pretty'] = sneaker_values[3]\n",
    "        \n",
    "    if no_additional_data == False:\n",
    "        sneaker_json.append(sneaker)\n",
    "        brand_json.append(brand)\n",
    "        secondary_brand_json.append(secondary_brand)\n",
    "        silhouette_json.append(silhouette)\n",
    "        \n",
    "    else:\n",
    "        sneaker_json.append(sneaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "while urls:\n",
    "    \n",
    "    current_url = random.choice(urls)\n",
    "    \n",
    "    try:\n",
    "        source = requests.get(current_url, time.sleep(3)).text\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    source_soup = BeautifulSoup(source)\n",
    "    monthly_sneakers = source_soup.find_all('div', class_='col-xs-12 col-sm-6')\n",
    "    \n",
    "    for index, sneaker in enumerate(monthly_sneakers):\n",
    "        if index % 2:\n",
    "            continue\n",
    "            \n",
    "        sneaker_url = solecollector_com + monthly_sneakers[index].a['href']\n",
    "        sneaker_html = requests.get(sneaker_url).text\n",
    "        sneaker_soup = BeautifulSoup(sneaker_html)\n",
    "        \n",
    "        try:\n",
    "            sneaker_script = str(sneaker_soup.find_all('script', type=\"text/javascript\")[2])\n",
    "        except IndexError:\n",
    "            break\n",
    "        get_data(sneaker_soup, sneaker_script)\n",
    "    \n",
    "    urls.remove(current_url)\n",
    "    print(len(urls))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/01_raw/sneaker.json', 'w') as outfile:\n",
    "    json.dump(sneaker_json, outfile)\n",
    "\n",
    "sneaker_df = pd.DataFrame(sneaker_json)\n",
    "sneaker_df = sneaker_df.sort_values(by='release_date', ascending=False)\n",
    "sneaker_df.to_csv('/Users/nikhilbhargava/Documents/sneakairs/data/01_raw/solecollector/sneaker.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/01_raw/brand.json', 'w') as outfile:\n",
    "    json.dump(brand_json, outfile)\n",
    "\n",
    "brand_df = pd.DataFrame(brand_json)\n",
    "brand_df = brand_df.sort_values(by='id', ascending=True)\n",
    "brand_df.to_csv('/Users/nikhilbhargava/Documents/sneakairs/data/01_raw/solecollector/brand.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/01_raw/secondary_brand.json', 'w') as outfile:\n",
    "    json.dump(secondary_brand_json, outfile)\n",
    "\n",
    "secondary_brand_df = pd.DataFrame(secondary_brand_json)\n",
    "secondary_brand_df = secondary_brand_df.sort_values(by='id', ascending=True)\n",
    "secondary_brand_df.to_csv('/Users/nikhilbhargava/Documents/sneakairs/data/01_raw/solecollector/secondary_brand.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/01_raw/silhouette.json.csv', 'w') as outfile:\n",
    "    json.dump(silhouette_json, outfile)\n",
    "\n",
    "silhouette_df = pd.DataFrame(silhouette_json)\n",
    "silhouette_df = silhouette_df.sort_values(by='id', ascending=True)\n",
    "silhouette_df.to_csv('/Users/nikhilbhargava/Documents/sneakairs/data/01_raw/solecollector/silhouette.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
